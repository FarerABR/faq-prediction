{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a69be43",
   "metadata": {},
   "source": [
    "# STS vs LLM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5365811",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5306c26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from textwrap import dedent\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from vllm import LLM, SamplingParams # type: ignore\n",
    "import gc\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ.setdefault(\"VLLM_LOG_LEVEL\", \"ERROR\")\n",
    "logging.getLogger(\"vllm\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba67c906",
   "metadata": {},
   "source": [
    "## Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29d03dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'Ka-ChatBot_BenchMark.xlsx'\n",
    "faq_ex = pd.read_excel(file_path, sheet_name='faq')\n",
    "samples_ex = pd.read_excel(file_path, sheet_name='samples')\n",
    "labels = samples_ex['gt_idx'].to_list()\n",
    "VALID_FAQ_IDS = set(faq_ex[\"idx\"].tolist())\n",
    "faq_lookup = faq_ex.set_index(\"idx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808b103d",
   "metadata": {},
   "source": [
    "## Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "916cdcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizer(text) -> str:\n",
    "\tif text is None:\n",
    "\t\treturn \"\"\n",
    "\tt = str(text)\n",
    "\tt = t.replace(\"ي\", \"ی\").replace(\"ك\", \"ک\")\n",
    "\tt = t.replace(\"\\u200c\", \" \").replace(\"\\u200f\", \"\").replace(\"\\u200a\", \"\")\n",
    "\tt = \" \".join(t.split())\n",
    "\treturn t\n",
    "\n",
    "\n",
    "FEW_SHOT_BLOCKS = {\n",
    "\t\"en\": dedent(\"\"\"\\\n",
    "Example 1\n",
    "Allowed idx list: [101, 305]\n",
    "FAQ list:\n",
    "idx=101: Resetting email or portal password.\n",
    "idx=305: Tracking the status of an online order.\n",
    "Query:\n",
    "I forgot the password to my email portal.\n",
    "Valid JSON:\n",
    "{\"idx\": 101}\n",
    "\n",
    "Example 2\n",
    "Allowed idx list: [12, 77]\n",
    "FAQ list:\n",
    "idx=12: Updating the billing address on my account.\n",
    "idx=77: Canceling an active subscription or plan.\n",
    "Query:\n",
    "Please cancel my current subscription immediately.\n",
    "Valid JSON:\n",
    "{\"idx\": 77}\n",
    "\"\"\"),\n",
    "\t\"fa\": dedent(\"\"\"\\\n",
    "مثال ۱\n",
    "لیست idx مجاز: [101, 305]\n",
    "لیست FAQ:\n",
    "idx=101: بازیابی یا تغییر رمز عبور ایمیل یا پنل کاربری.\n",
    "idx=305: پیگیری وضعیت سفارش اینترنتی.\n",
    "پرسش:\n",
    "رمز عبور پنل ایمیلم را فراموش کرده‌ام.\n",
    "خروجی JSON معتبر:\n",
    "{\"idx\": 101}\n",
    "\n",
    "مثال ۲\n",
    "لیست idx مجاز: [12, 77]\n",
    "لیست FAQ:\n",
    "idx=12: تغییر آدرس صورت‌حساب در حساب کاربری.\n",
    "idx=77: لغو اشتراک یا طرح فعال.\n",
    "پرسش:\n",
    "لطفاً اشتراک فعلی من را لغو کنید.\n",
    "خروجی JSON معتبر:\n",
    "{\"idx\": 77}\n",
    "\"\"\"),\n",
    "}\n",
    "\n",
    "PROMPT_RULES = {\n",
    "\t\"en\": dedent(\"\"\"\\\n",
    "You are a strict classifier. Always output exactly one valid JSON object and nothing else.\n",
    "Rules:\n",
    "1) Select exactly one idx from the allowed list.\n",
    "2) The response must match this schema exactly: {{\"idx\": <integer from the allowed list>}}.\n",
    "3) Do NOT write explanations, code fences, or extra words.\n",
    "4) If unsure, pick the idx that best matches the query; never return null.\n",
    "\n",
    "Here are correct examples you must imitate:\n",
    "{few_shot}\n",
    "\n",
    "Now solve the real task.\n",
    "Allowed idx list: [{allowed_ids}]\n",
    "FAQ list:\n",
    "{faq_block}\n",
    "\n",
    "Query:\n",
    "{query}\n",
    "\n",
    "Return ONLY the JSON object.\n",
    "\"\"\"),\n",
    "\t\"fa\": dedent(\"\"\"\\\n",
    "شما یک دسته‌بند دقیق هستید. همیشه فقط یک شیء JSON معتبر تولید کنید و هیچ متن دیگری ننویسید.\n",
    "قوانین:\n",
    "1) دقیقاً یک idx از لیست مجاز انتخاب کنید.\n",
    "2) پاسخ باید دقیقاً با این قالب باشد: {{\"idx\": <عدد صحیح از لیست مجاز>}}.\n",
    "3) هیچ توضیحی، متن اضافه، کدفنس، یا علامت اضافی ننویسید.\n",
    "4) اگر مطمئن نیستید، بهترین گزینه را انتخاب کنید؛ هرگز null برنگردانید.\n",
    "\n",
    "این‌ها مثال‌های صحیح هستند و باید دقیقاً از آن‌ها تقلید کنید:\n",
    "{few_shot}\n",
    "\n",
    "اکنون مسئلهٔ واقعی را حل کنید.\n",
    "لیست idx مجاز: [{allowed_ids}]\n",
    "لیست FAQ:\n",
    "{faq_block}\n",
    "\n",
    "پرسش:\n",
    "{query}\n",
    "\n",
    "فقط و فقط شیء JSON را برگردانید.\n",
    "\"\"\"),\n",
    "}\n",
    "\n",
    "RETRY_SUFFIX = {\n",
    "\t\"en\": \"\\n\\nPrevious output was invalid. Reply again with ONLY: {\\\"idx\\\": <allowed integer>}.\",\n",
    "\t\"fa\": \"\\n\\nپاسخ قبلی نامعتبر بود. فقط همین را برگردانید: {\\\"idx\\\": <عدد صحیح از لیست مجاز>}.\",\n",
    "}\n",
    "\n",
    "GUIDED_REGEX = r'^\\s*\\{\\s*\"idx\"\\s*:\\s*\\d+\\s*\\}\\s*$'\n",
    "\n",
    "_DIGIT_TRANS = str.maketrans(\n",
    "\t\"۰۱۲۳۴۵۶۷۸۹٠١٢٣٤٥٦٧٨٩\",\n",
    "\t\"01234567890123456789\",\n",
    ")\n",
    "\n",
    "\n",
    "def to_ascii_digits(text: str) -> str:\n",
    "\treturn str(text).translate(_DIGIT_TRANS)\n",
    "\n",
    "\n",
    "def extract_json_like(text: str) -> str:\n",
    "\tt = text.strip()\n",
    "\tt = re.sub(r\"^```(?:json)?\\\\s*\", \"\", t, flags=re.IGNORECASE)\n",
    "\tt = re.sub(r\"\\\\s*```$\", \"\", t)\n",
    "\tl = t.find(\"{\")\n",
    "\tr = t.rfind(\"}\")\n",
    "\tif l != -1 and r != -1 and r > l:\n",
    "\t\treturn t[l : r + 1]\n",
    "\treturn t\n",
    "\n",
    "\n",
    "def build_prompt(language, faq_subset, sample, allowed_ids):\n",
    "\tif language not in PROMPT_RULES:\n",
    "\t\traise ValueError(f\"Unsupported language: {language}\")\n",
    "\tfaq_lines = []\n",
    "\tfor idx, r in faq_subset.iterrows():\n",
    "\t\tfaq_lines.append(f\"idx={int(idx)}: {normalizer(r['faq'])}\")\n",
    "\tfaq_block = \"\\n\".join(faq_lines)\n",
    "\tsample_text = normalizer(sample)\n",
    "\tallowed_str = \", \".join(str(int(i)) for i in allowed_ids)\n",
    "\tprompt = PROMPT_RULES[language].format(\n",
    "\t\tfew_shot=FEW_SHOT_BLOCKS[language],\n",
    "\t\tallowed_ids=allowed_str,\n",
    "\t\tfaq_block=faq_block,\n",
    "\t\tquery=sample_text,\n",
    "\t)\n",
    "\treturn prompt\n",
    "\n",
    "\n",
    "def parse_idx(text):\n",
    "\tt = to_ascii_digits(text)\n",
    "\tt = extract_json_like(t)\n",
    "\ttry:\n",
    "\t\tobj = json.loads(t.strip())\n",
    "\t\tidx = obj.get(\"idx\", None)\n",
    "\t\tidx = int(idx)\n",
    "\t\treturn (idx, idx in VALID_FAQ_IDS)\n",
    "\texcept Exception:\n",
    "\t\tpass\n",
    "\tm = re.search(r'idx\\s*[:=]\\s*(\"?)(\\d+)\\1', t)\n",
    "\tif m:\n",
    "\t\tidx = int(m.group(2))\n",
    "\t\treturn (idx, idx in VALID_FAQ_IDS)\n",
    "\tm = re.search(r'^\\s*\\{\\s*\"idx\"\\s*:\\s*(\\d+)\\s*\\}\\s*$', t)\n",
    "\tif m:\n",
    "\t\tidx = int(m.group(1))\n",
    "\t\treturn (idx, idx in VALID_FAQ_IDS)\n",
    "\treturn (None, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9fe750",
   "metadata": {},
   "source": [
    "## STS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd9ac50",
   "metadata": {},
   "source": [
    "### model: multilingual-e5-base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8f7c7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"intfloat/multilingual-e5-base\"\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdee2b23",
   "metadata": {},
   "source": [
    "### embeding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7534d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 37.50it/s]\n",
      "Batches: 100%|██████████| 2/2 [00:00<00:00,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STS Accuracy: 0.5914, Error Rate: 0.4086\n",
      "\n",
      "Ground Truth vs STS result: (top 10 samples)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt_idx</th>\n",
       "      <th>sts_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gt_idx  sts_idx\n",
       "0       1        1\n",
       "1       1        6\n",
       "2       1        1\n",
       "3       1        1\n",
       "4       1       20\n",
       "5       1        1\n",
       "6       1       20\n",
       "7       1       20\n",
       "8       2        3\n",
       "9       2        3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong samples with lowest STS scores: (top 10 samples out of 38)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>gt_idx</th>\n",
       "      <th>sts_idx</th>\n",
       "      <th>sts_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>چکونه میتوان رمزعبورراتعقیرداد</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>0.809970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>چگونه شماره موبایل خود را تایید کنم</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.824448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>سلام خسته نباشید من برام از برنامه پیام اومد و...</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>0.830442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>سلام \\nشماره همراهی که به بانک معرفی کرده بودن...</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0.836262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>سلام روز بخیر شرایط دریافت وام با امتیاز به چه...</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>0.838129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>سلام خسته نباشید \\nبنده برای وام ازدواج اقدام ...</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>0.838673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>سلام\\nخسته نباشید\\nمیخواستم بدانم که پرداخت اق...</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.840247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>سلام وقت بخیر\\nچجوری میتونم یک حساب جدید از طر...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.840808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>سلام روزبخیر\\nچرا دسترسی به فایل حسابهای سالها...</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>0.843183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>سلام خسته نباشید امتیاز تسهیلات من چرا زیاد نم...</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0.843339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sample  gt_idx  sts_idx  \\\n",
       "63                     چکونه میتوان رمزعبورراتعقیرداد      13        9   \n",
       "26                چگونه شماره موبایل خود را تایید کنم       5        3   \n",
       "69  سلام خسته نباشید من برام از برنامه پیام اومد و...      16       20   \n",
       "19  سلام \\nشماره همراهی که به بانک معرفی کرده بودن...       5       13   \n",
       "61  سلام روز بخیر شرایط دریافت وام با امتیاز به چه...      12        8   \n",
       "80  سلام خسته نباشید \\nبنده برای وام ازدواج اقدام ...      21       16   \n",
       "42  سلام\\nخسته نباشید\\nمیخواستم بدانم که پرداخت اق...       8        4   \n",
       "8   سلام وقت بخیر\\nچجوری میتونم یک حساب جدید از طر...       2        3   \n",
       "73  سلام روزبخیر\\nچرا دسترسی به فایل حسابهای سالها...      18        5   \n",
       "58  سلام خسته نباشید امتیاز تسهیلات من چرا زیاد نم...      11       10   \n",
       "\n",
       "    sts_score  \n",
       "63   0.809970  \n",
       "26   0.824448  \n",
       "69   0.830442  \n",
       "19   0.836262  \n",
       "61   0.838129  \n",
       "80   0.838673  \n",
       "42   0.840247  \n",
       "8    0.840808  \n",
       "73   0.843183  \n",
       "58   0.843339  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "faq_inputs = [f\"passage: {t}\" for t in faq_ex['faq'].apply(normalizer).to_list()]\n",
    "sample_inputs = [f\"query: {t}\" for t in samples_ex['sample'].apply(normalizer).to_list()]\n",
    "\n",
    "\n",
    "faq_enc = model.encode(faq_inputs, batch_size=64, normalize_embeddings=True, show_progress_bar=True)\n",
    "sample_enc = model.encode(sample_inputs, batch_size=64, normalize_embeddings=True, show_progress_bar=True)\n",
    "\n",
    "S = faq_enc @ sample_enc.T\n",
    "\n",
    "best_j = np.argmax(S, axis=0)\n",
    "top1_score = S[best_j, np.arange(S.shape[1])]\n",
    "pred_idx_sts = [faq_ex['idx'][j] for j in best_j]\n",
    "\n",
    "samples_ex['sts_idx'] = pred_idx_sts\n",
    "samples_ex['sts_score'] = top1_score\n",
    "\n",
    "acc = (samples_ex['sts_idx'] == samples_ex['gt_idx']).mean()\n",
    "err = 1 - acc\n",
    "print(f\"STS Accuracy: {acc:.4f}, Error Rate: {err:.4f}\")\n",
    "\n",
    "print(\"\\nGround Truth vs STS result: (top 10 samples)\")\n",
    "display(samples_ex[['gt_idx','sts_idx']].head(10))\n",
    "\n",
    "wrong = samples_ex[samples_ex[\"sts_idx\"] != samples_ex[\"gt_idx\"]].copy()\n",
    "print(f\"Wrong samples with lowest STS scores: (top 10 samples out of {len(wrong)})\")\n",
    "wrong_sorted = wrong.sort_values(\"sts_score\", ascending=True).head(10)\n",
    "display(wrong_sorted[[\"sample\", \"gt_idx\", \"sts_idx\", \"sts_score\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22356102",
   "metadata": {},
   "source": [
    "### top-k acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1fa6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 0.5914\n",
      "Top-3 Accuracy: 0.8387\n",
      "Top-5 Accuracy: 0.8925\n"
     ]
    }
   ],
   "source": [
    "def acc_top_k(S,faq, samples, k=3):\n",
    "\tfaq_idx = faq['idx'].to_numpy()\n",
    "\tgt_idx = samples['gt_idx'].to_numpy()\n",
    "\t\n",
    "\ttopk_rows = np.argsort(-S, axis=0)[:k, :]\n",
    "\ttopk_idx = faq_idx[topk_rows]\n",
    "\thit = (topk_idx == gt_idx).any(axis=0)\n",
    "\t\n",
    "\treturn hit.mean(), topk_idx\n",
    "\n",
    "for k in [1, 3, 5]:\n",
    "\tacc, top_idxs = acc_top_k(S, faq_ex, samples_ex, k=k)\n",
    "\tprint(f\"Top-{k} Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fc8bf2",
   "metadata": {},
   "source": [
    "### classification report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "632d8067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.50      0.57         8\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.33      0.67      0.44         3\n",
      "           5       0.78      0.70      0.74        10\n",
      "           6       0.50      0.43      0.46         7\n",
      "           7       0.50      0.50      0.50         2\n",
      "           8       0.57      0.57      0.57         7\n",
      "           9       0.83      1.00      0.91         5\n",
      "          10       0.86      0.86      0.86         7\n",
      "          11       0.00      0.00      0.00         4\n",
      "          12       0.50      0.33      0.40         3\n",
      "          13       0.00      0.00      0.00         2\n",
      "          14       1.00      0.50      0.67         2\n",
      "          15       1.00      1.00      1.00         3\n",
      "          16       0.00      0.00      0.00         2\n",
      "          17       1.00      0.50      0.67         2\n",
      "          18       1.00      0.50      0.67         2\n",
      "          19       0.67      1.00      0.80         2\n",
      "          20       0.20      1.00      0.33         3\n",
      "          21       1.00      0.71      0.83         7\n",
      "          22       1.00      1.00      1.00         2\n",
      "          23       1.00      1.00      1.00         3\n",
      "          24       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.59        93\n",
      "   macro avg       0.60      0.57      0.56        93\n",
      "weighted avg       0.63      0.59      0.59        93\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(samples_ex['gt_idx'].to_numpy(), samples_ex['sts_idx'].to_numpy(), labels=faq_ex['idx'].to_numpy(), zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab9e591",
   "metadata": {},
   "source": [
    "### save to xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578b1a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Ka-ChatBot_BenchMark.xlsx\n"
     ]
    }
   ],
   "source": [
    "with pd.ExcelWriter(file_path, engine=\"openpyxl\", mode='a', if_sheet_exists='replace') as writer:\n",
    "\tfaq_ex.to_excel(writer, sheet_name='faq', index=False)\n",
    "\tsamples_ex.to_excel(writer, sheet_name='samples', index=False)\n",
    "print(f\"Results saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66722357",
   "metadata": {},
   "source": [
    "## LLM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a36099",
   "metadata": {},
   "source": [
    "### llm models:\n",
    "\n",
    "- google/gemma-3-4b-it\n",
    "- Qwen/Qwen2.5-7B-Instruct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5843bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalute_llm(model, *, language, samples_df):\n",
    "\t# gemma-3 models require bf16; others can stay on fp16\n",
    "\tdtype = \"bfloat16\" if (\"gemma-3\" in model or \"gemma3\" in model) else \"half\"\n",
    "\t\n",
    "\tllm = LLM(\n",
    "\t\tmodel=model,\n",
    "\t\tdtype=dtype,\n",
    "\t\ttrust_remote_code=True,\n",
    "\t\tgpu_memory_utilization=0.9,\n",
    "\t\tmax_model_len=4096,\n",
    "\t)\n",
    "\n",
    "\ttry:\n",
    "\t\tsampling = SamplingParams(\n",
    "\t\t\ttemperature=0.0,\n",
    "\t\t\ttop_p=1.0,\n",
    "\t\t\tmax_tokens=32,\n",
    "\t\t\tstop=[\"\\n\\n\"],\n",
    "\t\t\tguided_regex=GUIDED_REGEX,\n",
    "\t\t)\n",
    "\texcept TypeError:\n",
    "\t\tsampling = SamplingParams(\n",
    "\t\t\ttemperature=0.0,\n",
    "\t\t\ttop_p=1.0,\n",
    "\t\t\tmax_tokens=32,\n",
    "\t\t\tstop=[\"\\n\\n\"],\n",
    "\t\t)\n",
    " \n",
    "\tdef run_llm(prompts):\n",
    "\t\touts = llm.generate(prompts, sampling_params=sampling)\n",
    "\t\treturn [o.outputs[0].text for o in outs]\n",
    "\n",
    "\tsample_texts = samples_df['sample'].to_list()\n",
    "\tall_ids = [int(i) for i in faq_lookup.index.tolist()]\n",
    "\tfaq_subset_all = faq_lookup.loc[all_ids]\n",
    "\tcandidate_lists = [all_ids for _ in sample_texts]\n",
    "\tprompts = [build_prompt(language, faq_subset_all, sample_text, all_ids) for sample_text in sample_texts]\n",
    "\n",
    "\tt0 = time.time()\n",
    "\traw = run_llm(prompts)\n",
    "\tt1 = time.time() - t0\n",
    "\tprint(f\"[{language}] LLM total time: {t1:.2f}s | per sample: {1000*t1/len(prompts):.1f} ms\")\n",
    "\t\n",
    "\tpred = [None] * len(prompts)\n",
    "\tok = [False] * len(prompts)\n",
    "\tallowed_sets = [set(ids) for ids in candidate_lists]\n",
    "\n",
    "\tdef parse_and_store(i, text):\n",
    "\t\tidx, parse_ok = parse_idx(text)\n",
    "\t\tif parse_ok and idx not in allowed_sets[i]:\n",
    "\t\t\tparse_ok = False\n",
    "\t\t\tidx = None\n",
    "\t\tpred[i] = idx\n",
    "\t\tok[i] = parse_ok\n",
    "\n",
    "\tfor i, out in enumerate(raw):\n",
    "\t\tparse_and_store(i, out)\n",
    "\n",
    "\tmax_retries = 1\n",
    "\tfor _ in range(max_retries):\n",
    "\t\tretry_ids = [i for i, flag in enumerate(ok) if not flag]\n",
    "\t\tif not retry_ids:\n",
    "\t\t\tbreak\n",
    "\t\tretry_prompts = [\n",
    "\t\t\tprompts[i] + RETRY_SUFFIX[language]\n",
    "\t\t\tfor i in retry_ids\n",
    "\t\t]\n",
    "\t\tretry_raw = run_llm(retry_prompts)\n",
    "\t\tfor row_idx, out in zip(retry_ids, retry_raw):\n",
    "\t\t\traw[row_idx] = out\n",
    "\t\t\tparse_and_store(row_idx, out)\n",
    "\n",
    "\ty_pred = np.array(pred, dtype=object)\n",
    "  \n",
    "\tacc = (y_pred == samples_df['gt_idx']).mean()\n",
    "\terr = 1 - acc\n",
    "\tok_rate = float(np.mean(ok))\n",
    "\tok_mask = np.array(ok, dtype=bool)\n",
    "\n",
    "\tlabels = faq_ex[\"idx\"].to_numpy()\n",
    "\tif ok_mask.any():\n",
    "\t\ty_pred_ok = y_pred[ok_mask].astype(labels.dtype, copy=False)\n",
    "\t\ty_true_ok = samples_df['gt_idx'][ok_mask].astype(labels.dtype, copy=False)\n",
    "\t\treport_ok = classification_report(y_true_ok, y_pred_ok, labels=labels, zero_division=0)\n",
    "\telse:\n",
    "\t\treport_ok = \"No parseable outputs (parse_ok_rate=0).\"\n",
    "  \n",
    "\tdel llm\n",
    "\tgc.collect()\n",
    "\ttry:\n",
    "\t\ttorch.cuda.empty_cache()\n",
    "\texcept Exception:\n",
    "\t\tpass\n",
    "\n",
    "\treturn {\n",
    "\t\t\"language\": language,\n",
    "\t\t\"model\": model,\n",
    "\t\t\"n_samples\": len(prompts),\n",
    "\t\t\"total_time_s\": t1,\n",
    "\t\t\"ms_per_sample\": 1000.0 * t1 / max(1, len(prompts)),\n",
    "\t\t\"acc\": float(acc),\n",
    "\t\t\"err\": float(err),\n",
    "\t\t\"parse_ok_rate\": ok_rate,\n",
    "\t\t\"raw\": raw,\n",
    "\t\t\"pred\": pred,\n",
    "\t\t\"ok\": ok,\n",
    "\t\t\"report_parse_ok_only\": report_ok,\n",
    "\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2dcb074b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running language: en ===\n",
      "Evaluating LLM model: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m(EngineCore_DP0 pid=51427)\u001b[0;0m Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "\u001b[0;36m(EngineCore_DP0 pid=51427)\u001b[0;0m /home/shadeform/.pyenv/versions/3.13.0/lib/python3.13/site-packages/tvm_ffi/_optional_torch_c_dlpack.py:174: UserWarning: Failed to JIT torch c dlpack extension, EnvTensorAllocator will not be enabled.\n",
      "\u001b[0;36m(EngineCore_DP0 pid=51427)\u001b[0;0m We recommend installing via `pip install torch-c-dlpack-ext`\n",
      "\u001b[0;36m(EngineCore_DP0 pid=51427)\u001b[0;0m   warnings.warn(\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.57it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.64s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:02<00:00,  1.49s/it]\n",
      "\u001b[0;36m(EngineCore_DP0 pid=51427)\u001b[0;0m \n",
      "\u001b[0;36m(EngineCore_DP0 pid=51427)\u001b[0;0m /home/shadeform/.pyenv/versions/3.13.0/lib/python3.13/site-packages/torch/_dynamo/guards.py:1114: RuntimeWarning: Guards may run slower on Python 3.13.0. Consider upgrading to Python 3.13.1+.\n",
      "\u001b[0;36m(EngineCore_DP0 pid=51427)\u001b[0;0m   warnings.warn(\n",
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:03<00:00, 16.40it/s]\n",
      "Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:02<00:00, 16.73it/s]\n",
      "Adding requests: 100%|██████████| 93/93 [00:00<00:00, 735.68it/s]\n",
      "Processed prompts: 100%|██████████| 93/93 [00:01<00:00, 80.11it/s, est. speed input: 67300.26 toks/s, output: 1001.42 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[en] LLM total time: 1.29s | per sample: 13.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.7849 err=0.2151 parse_ok_rate=1.0000\n",
      "time=1.29s | 13.9 ms/sample\n",
      "\n",
      "Classification report (parse_ok only):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         8\n",
      "           2       0.50      1.00      0.67         2\n",
      "           3       1.00      0.75      0.86         4\n",
      "           4       1.00      1.00      1.00         3\n",
      "           5       1.00      0.60      0.75        10\n",
      "           6       0.86      0.86      0.86         7\n",
      "           7       1.00      0.50      0.67         2\n",
      "           8       1.00      1.00      1.00         7\n",
      "           9       0.62      1.00      0.77         5\n",
      "          10       1.00      0.57      0.73         7\n",
      "          11       0.50      1.00      0.67         4\n",
      "          12       1.00      0.33      0.50         3\n",
      "          13       0.33      1.00      0.50         2\n",
      "          14       0.67      1.00      0.80         2\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       0.00      0.00      0.00         2\n",
      "          17       0.33      0.50      0.40         2\n",
      "          18       1.00      0.50      0.67         2\n",
      "          19       0.67      1.00      0.80         2\n",
      "          20       0.75      1.00      0.86         3\n",
      "          21       1.00      1.00      1.00         7\n",
      "          22       1.00      1.00      1.00         2\n",
      "          23       1.00      1.00      1.00         3\n",
      "          24       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.78        93\n",
      "   macro avg       0.72      0.73      0.69        93\n",
      "weighted avg       0.82      0.78      0.77        93\n",
      "\n",
      "Evaluating LLM model: Qwen/Qwen2.5-7B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m(EngineCore_DP0 pid=51777)\u001b[0;0m /home/shadeform/.pyenv/versions/3.13.0/lib/python3.13/site-packages/tvm_ffi/_optional_torch_c_dlpack.py:174: UserWarning: Failed to JIT torch c dlpack extension, EnvTensorAllocator will not be enabled.\n",
      "\u001b[0;36m(EngineCore_DP0 pid=51777)\u001b[0;0m We recommend installing via `pip install torch-c-dlpack-ext`\n",
      "\u001b[0;36m(EngineCore_DP0 pid=51777)\u001b[0;0m   warnings.warn(\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.12s/it]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.21s/it]\n",
      "Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.20s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.22s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.21s/it]\n",
      "\u001b[0;36m(EngineCore_DP0 pid=51777)\u001b[0;0m \n",
      "\u001b[0;36m(EngineCore_DP0 pid=51777)\u001b[0;0m /home/shadeform/.pyenv/versions/3.13.0/lib/python3.13/site-packages/torch/_dynamo/guards.py:1114: RuntimeWarning: Guards may run slower on Python 3.13.0. Consider upgrading to Python 3.13.1+.\n",
      "\u001b[0;36m(EngineCore_DP0 pid=51777)\u001b[0;0m   warnings.warn(\n",
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:05<00:00, 10.08it/s]\n",
      "Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:02<00:00, 12.10it/s]\n",
      "Adding requests: 100%|██████████| 93/93 [00:00<00:00, 623.34it/s]\n",
      "Processed prompts: 100%|██████████| 93/93 [00:03<00:00, 25.66it/s, est. speed input: 29429.73 toks/s, output: 205.29 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[en] LLM total time: 3.78s | per sample: 40.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.8065 err=0.1935 parse_ok_rate=1.0000\n",
      "time=3.78s | 40.6 ms/sample\n",
      "\n",
      "Classification report (parse_ok only):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      1.00      0.89         8\n",
      "           2       0.50      1.00      0.67         2\n",
      "           3       0.75      0.75      0.75         4\n",
      "           4       1.00      1.00      1.00         3\n",
      "           5       1.00      0.70      0.82        10\n",
      "           6       1.00      0.57      0.73         7\n",
      "           7       0.25      0.50      0.33         2\n",
      "           8       1.00      1.00      1.00         7\n",
      "           9       0.71      1.00      0.83         5\n",
      "          10       1.00      0.86      0.92         7\n",
      "          11       0.50      0.75      0.60         4\n",
      "          12       0.00      0.00      0.00         3\n",
      "          13       1.00      0.50      0.67         2\n",
      "          14       0.50      1.00      0.67         2\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       0.50      1.00      0.67         2\n",
      "          17       1.00      0.50      0.67         2\n",
      "          18       1.00      1.00      1.00         2\n",
      "          19       1.00      1.00      1.00         2\n",
      "          20       1.00      1.00      1.00         3\n",
      "          21       1.00      1.00      1.00         7\n",
      "          22       1.00      1.00      1.00         2\n",
      "          23       1.00      1.00      1.00         3\n",
      "          24       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.81        93\n",
      "   macro avg       0.77      0.80      0.76        93\n",
      "weighted avg       0.82      0.81      0.79        93\n",
      "\n",
      "\n",
      "=== Running language: fa ===\n",
      "Evaluating LLM model: google/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m(EngineCore_DP0 pid=52132)\u001b[0;0m Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "\u001b[0;36m(EngineCore_DP0 pid=52132)\u001b[0;0m /home/shadeform/.pyenv/versions/3.13.0/lib/python3.13/site-packages/tvm_ffi/_optional_torch_c_dlpack.py:174: UserWarning: Failed to JIT torch c dlpack extension, EnvTensorAllocator will not be enabled.\n",
      "\u001b[0;36m(EngineCore_DP0 pid=52132)\u001b[0;0m We recommend installing via `pip install torch-c-dlpack-ext`\n",
      "\u001b[0;36m(EngineCore_DP0 pid=52132)\u001b[0;0m   warnings.warn(\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  1.60it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.58it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:01<00:00,  1.58it/s]\n",
      "\u001b[0;36m(EngineCore_DP0 pid=52132)\u001b[0;0m \n",
      "\u001b[0;36m(EngineCore_DP0 pid=52132)\u001b[0;0m /home/shadeform/.pyenv/versions/3.13.0/lib/python3.13/site-packages/torch/_dynamo/guards.py:1114: RuntimeWarning: Guards may run slower on Python 3.13.0. Consider upgrading to Python 3.13.1+.\n",
      "\u001b[0;36m(EngineCore_DP0 pid=52132)\u001b[0;0m   warnings.warn(\n",
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:03<00:00, 16.16it/s]\n",
      "Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:02<00:00, 16.19it/s]\n",
      "Adding requests: 100%|██████████| 93/93 [00:00<00:00, 887.59it/s]\n",
      "Processed prompts: 100%|██████████| 93/93 [00:01<00:00, 79.96it/s, est. speed input: 74524.62 toks/s, output: 675.17 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fa] LLM total time: 1.27s | per sample: 13.7 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.7312 err=0.2688 parse_ok_rate=1.0000\n",
      "time=1.27s | 13.7 ms/sample\n",
      "\n",
      "Classification report (parse_ok only):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      1.00      0.94         8\n",
      "           2       0.67      1.00      0.80         2\n",
      "           3       1.00      0.75      0.86         4\n",
      "           4       1.00      1.00      1.00         3\n",
      "           5       0.80      0.40      0.53        10\n",
      "           6       0.83      0.71      0.77         7\n",
      "           7       0.50      0.50      0.50         2\n",
      "           8       1.00      1.00      1.00         7\n",
      "           9       0.38      1.00      0.56         5\n",
      "          10       0.86      0.86      0.86         7\n",
      "          11       0.50      0.75      0.60         4\n",
      "          12       1.00      0.33      0.50         3\n",
      "          13       0.40      1.00      0.57         2\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       0.00      0.00      0.00         2\n",
      "          17       0.33      0.50      0.40         2\n",
      "          18       1.00      0.50      0.67         2\n",
      "          19       0.50      0.50      0.50         2\n",
      "          20       0.60      1.00      0.75         3\n",
      "          21       1.00      1.00      1.00         7\n",
      "          22       1.00      1.00      1.00         2\n",
      "          23       1.00      1.00      1.00         3\n",
      "          24       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.73        93\n",
      "   macro avg       0.64      0.66      0.62        93\n",
      "weighted avg       0.74      0.73      0.70        93\n",
      "\n",
      "Evaluating LLM model: Qwen/Qwen2.5-7B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;36m(EngineCore_DP0 pid=52469)\u001b[0;0m /home/shadeform/.pyenv/versions/3.13.0/lib/python3.13/site-packages/tvm_ffi/_optional_torch_c_dlpack.py:174: UserWarning: Failed to JIT torch c dlpack extension, EnvTensorAllocator will not be enabled.\n",
      "\u001b[0;36m(EngineCore_DP0 pid=52469)\u001b[0;0m We recommend installing via `pip install torch-c-dlpack-ext`\n",
      "\u001b[0;36m(EngineCore_DP0 pid=52469)\u001b[0;0m   warnings.warn(\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:01<00:03,  1.09s/it]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:02<00:02,  1.21s/it]\n",
      "Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:03<00:01,  1.20s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.24s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:04<00:00,  1.22s/it]\n",
      "\u001b[0;36m(EngineCore_DP0 pid=52469)\u001b[0;0m \n",
      "\u001b[0;36m(EngineCore_DP0 pid=52469)\u001b[0;0m /home/shadeform/.pyenv/versions/3.13.0/lib/python3.13/site-packages/torch/_dynamo/guards.py:1114: RuntimeWarning: Guards may run slower on Python 3.13.0. Consider upgrading to Python 3.13.1+.\n",
      "\u001b[0;36m(EngineCore_DP0 pid=52469)\u001b[0;0m   warnings.warn(\n",
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 51/51 [00:05<00:00, 10.09it/s]\n",
      "Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:02<00:00, 12.00it/s]\n",
      "Adding requests: 100%|██████████| 93/93 [00:00<00:00, 561.18it/s]\n",
      "Processed prompts: 100%|██████████| 93/93 [00:03<00:00, 23.47it/s, est. speed input: 33309.26 toks/s, output: 246.63 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fa] LLM total time: 4.13s | per sample: 44.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 15/15 [00:00<00:00, 531.32it/s]\n",
      "Processed prompts: 100%|██████████| 15/15 [00:02<00:00,  7.02it/s, est. speed input: 10451.25 toks/s, output: 165.68 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.6774 err=0.3226 parse_ok_rate=0.8925\n",
      "time=4.13s | 44.4 ms/sample\n",
      "\n",
      "Classification report (parse_ok only):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.50      0.57         4\n",
      "           2       0.29      1.00      0.44         2\n",
      "           3       0.75      1.00      0.86         3\n",
      "           4       1.00      1.00      1.00         3\n",
      "           5       1.00      0.50      0.67        10\n",
      "           6       1.00      0.67      0.80         6\n",
      "           7       0.33      0.50      0.40         2\n",
      "           8       1.00      1.00      1.00         7\n",
      "           9       1.00      0.60      0.75         5\n",
      "          10       1.00      1.00      1.00         4\n",
      "          11       0.60      0.75      0.67         4\n",
      "          12       0.00      0.00      0.00         2\n",
      "          13       0.40      1.00      0.57         2\n",
      "          14       0.33      0.50      0.40         2\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       0.50      1.00      0.67         2\n",
      "          17       1.00      0.50      0.67         2\n",
      "          18       1.00      1.00      1.00         2\n",
      "          19       0.67      1.00      0.80         2\n",
      "          20       0.75      1.00      0.86         3\n",
      "          21       1.00      1.00      1.00         7\n",
      "          22       1.00      1.00      1.00         2\n",
      "          23       1.00      1.00      1.00         3\n",
      "          24       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.76        83\n",
      "   macro avg       0.72      0.77      0.71        83\n",
      "weighted avg       0.80      0.76      0.75        83\n",
      "\n",
      "\n",
      "Samples (EN) preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>gt_idx</th>\n",
       "      <th>sts_idx</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>llm_idx__google_gemma_3_4b_it</th>\n",
       "      <th>llm_ok__google_gemma_3_4b_it</th>\n",
       "      <th>llm_idx__Qwen_Qwen2.5_7b_Instruct</th>\n",
       "      <th>llm_ok__Qwen_Qwen2.5_7b_Instruct</th>\n",
       "      <th>llm_idx__en__google_gemma_3_4b_it</th>\n",
       "      <th>llm_ok__en__google_gemma_3_4b_it</th>\n",
       "      <th>llm_idx__en__Qwen_Qwen2.5_7B_Instruct</th>\n",
       "      <th>llm_ok__en__Qwen_Qwen2.5_7B_Instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>سلام وقت بخیر  من میخوام افتتاح حساب کنم ولی ت...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.885865</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>سلام من کارت ملی ندارم\\nاما شناسنامه عکسدار و ...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.856472</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>درود  وقت بخیر برای افتتاح حساب تو قسمت احراز ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.870513</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سلام عکس روی شناسنامه من بدون ریشه وای الان ری...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.853145</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>سلام من بدا یز ثبت نام مشکل دارم من در بانک  ب...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.858814</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sample  gt_idx  sts_idx  \\\n",
       "0  سلام وقت بخیر  من میخوام افتتاح حساب کنم ولی ت...       1        1   \n",
       "1  سلام من کارت ملی ندارم\\nاما شناسنامه عکسدار و ...       1        6   \n",
       "2  درود  وقت بخیر برای افتتاح حساب تو قسمت احراز ...       1        1   \n",
       "3  سلام عکس روی شناسنامه من بدون ریشه وای الان ری...       1        1   \n",
       "4  سلام من بدا یز ثبت نام مشکل دارم من در بانک  ب...       1       20   \n",
       "\n",
       "   sts_score  llm_idx__google_gemma_3_4b_it  llm_ok__google_gemma_3_4b_it  \\\n",
       "0   0.885865                              1                          True   \n",
       "1   0.856472                              1                          True   \n",
       "2   0.870513                              1                          True   \n",
       "3   0.853145                              1                          True   \n",
       "4   0.858814                              1                          True   \n",
       "\n",
       "   llm_idx__Qwen_Qwen2.5_7b_Instruct  llm_ok__Qwen_Qwen2.5_7b_Instruct  \\\n",
       "0                                NaN                             False   \n",
       "1                                2.0                              True   \n",
       "2                                NaN                             False   \n",
       "3                                NaN                             False   \n",
       "4                                NaN                             False   \n",
       "\n",
       "   llm_idx__en__google_gemma_3_4b_it  llm_ok__en__google_gemma_3_4b_it  \\\n",
       "0                                  1                              True   \n",
       "1                                  1                              True   \n",
       "2                                  1                              True   \n",
       "3                                  1                              True   \n",
       "4                                  1                              True   \n",
       "\n",
       "   llm_idx__en__Qwen_Qwen2.5_7B_Instruct  llm_ok__en__Qwen_Qwen2.5_7B_Instruct  \n",
       "0                                      1                                  True  \n",
       "1                                      1                                  True  \n",
       "2                                      1                                  True  \n",
       "3                                      1                                  True  \n",
       "4                                      1                                  True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples (FA) preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>gt_idx</th>\n",
       "      <th>sts_idx</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>llm_idx__google_gemma_3_4b_it</th>\n",
       "      <th>llm_ok__google_gemma_3_4b_it</th>\n",
       "      <th>llm_idx__Qwen_Qwen2.5_7b_Instruct</th>\n",
       "      <th>llm_ok__Qwen_Qwen2.5_7b_Instruct</th>\n",
       "      <th>llm_idx__fa__google_gemma_3_4b_it</th>\n",
       "      <th>llm_ok__fa__google_gemma_3_4b_it</th>\n",
       "      <th>llm_idx__fa__Qwen_Qwen2.5_7B_Instruct</th>\n",
       "      <th>llm_ok__fa__Qwen_Qwen2.5_7B_Instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>سلام وقت بخیر  من میخوام افتتاح حساب کنم ولی ت...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.885865</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>سلام من کارت ملی ندارم\\nاما شناسنامه عکسدار و ...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.856472</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>درود  وقت بخیر برای افتتاح حساب تو قسمت احراز ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.870513</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سلام عکس روی شناسنامه من بدون ریشه وای الان ری...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.853145</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>سلام من بدا یز ثبت نام مشکل دارم من در بانک  ب...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.858814</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sample  gt_idx  sts_idx  \\\n",
       "0  سلام وقت بخیر  من میخوام افتتاح حساب کنم ولی ت...       1        1   \n",
       "1  سلام من کارت ملی ندارم\\nاما شناسنامه عکسدار و ...       1        6   \n",
       "2  درود  وقت بخیر برای افتتاح حساب تو قسمت احراز ...       1        1   \n",
       "3  سلام عکس روی شناسنامه من بدون ریشه وای الان ری...       1        1   \n",
       "4  سلام من بدا یز ثبت نام مشکل دارم من در بانک  ب...       1       20   \n",
       "\n",
       "   sts_score  llm_idx__google_gemma_3_4b_it  llm_ok__google_gemma_3_4b_it  \\\n",
       "0   0.885865                              1                          True   \n",
       "1   0.856472                              1                          True   \n",
       "2   0.870513                              1                          True   \n",
       "3   0.853145                              1                          True   \n",
       "4   0.858814                              1                          True   \n",
       "\n",
       "   llm_idx__Qwen_Qwen2.5_7b_Instruct  llm_ok__Qwen_Qwen2.5_7b_Instruct  \\\n",
       "0                                NaN                             False   \n",
       "1                                2.0                              True   \n",
       "2                                NaN                             False   \n",
       "3                                NaN                             False   \n",
       "4                                NaN                             False   \n",
       "\n",
       "   llm_idx__fa__google_gemma_3_4b_it  llm_ok__fa__google_gemma_3_4b_it  \\\n",
       "0                                  1                              True   \n",
       "1                                  1                              True   \n",
       "2                                  1                              True   \n",
       "3                                  1                              True   \n",
       "4                                  1                              True   \n",
       "\n",
       "   llm_idx__fa__Qwen_Qwen2.5_7B_Instruct  llm_ok__fa__Qwen_Qwen2.5_7B_Instruct  \n",
       "0                                    NaN                                 False  \n",
       "1                                    2.0                                  True  \n",
       "2                                    1.0                                  True  \n",
       "3                                    NaN                                 False  \n",
       "4                                    NaN                                 False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined samples with prediction columns:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>gt_idx</th>\n",
       "      <th>sts_idx</th>\n",
       "      <th>sts_score</th>\n",
       "      <th>llm_idx__google_gemma_3_4b_it</th>\n",
       "      <th>llm_ok__google_gemma_3_4b_it</th>\n",
       "      <th>llm_idx__Qwen_Qwen2.5_7b_Instruct</th>\n",
       "      <th>llm_ok__Qwen_Qwen2.5_7b_Instruct</th>\n",
       "      <th>en_gemma</th>\n",
       "      <th>en_qwen</th>\n",
       "      <th>fa_gemma</th>\n",
       "      <th>fa_qwen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>سلام وقت بخیر  من میخوام افتتاح حساب کنم ولی ت...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.885865</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>سلام من کارت ملی ندارم\\nاما شناسنامه عکسدار و ...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.856472</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>درود  وقت بخیر برای افتتاح حساب تو قسمت احراز ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.870513</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سلام عکس روی شناسنامه من بدون ریشه وای الان ری...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.853145</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>سلام من بدا یز ثبت نام مشکل دارم من در بانک  ب...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.858814</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sample  gt_idx  sts_idx  \\\n",
       "0  سلام وقت بخیر  من میخوام افتتاح حساب کنم ولی ت...       1        1   \n",
       "1  سلام من کارت ملی ندارم\\nاما شناسنامه عکسدار و ...       1        6   \n",
       "2  درود  وقت بخیر برای افتتاح حساب تو قسمت احراز ...       1        1   \n",
       "3  سلام عکس روی شناسنامه من بدون ریشه وای الان ری...       1        1   \n",
       "4  سلام من بدا یز ثبت نام مشکل دارم من در بانک  ب...       1       20   \n",
       "\n",
       "   sts_score  llm_idx__google_gemma_3_4b_it  llm_ok__google_gemma_3_4b_it  \\\n",
       "0   0.885865                              1                          True   \n",
       "1   0.856472                              1                          True   \n",
       "2   0.870513                              1                          True   \n",
       "3   0.853145                              1                          True   \n",
       "4   0.858814                              1                          True   \n",
       "\n",
       "   llm_idx__Qwen_Qwen2.5_7b_Instruct  llm_ok__Qwen_Qwen2.5_7b_Instruct  \\\n",
       "0                                NaN                             False   \n",
       "1                                2.0                              True   \n",
       "2                                NaN                             False   \n",
       "3                                NaN                             False   \n",
       "4                                NaN                             False   \n",
       "\n",
       "   en_gemma  en_qwen  fa_gemma  fa_qwen  \n",
       "0         1        1         1      NaN  \n",
       "1         1        1         1      2.0  \n",
       "2         1        1         1      1.0  \n",
       "3         1        1         1      NaN  \n",
       "4         1        1         1      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics (EN):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>model</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>total_time_s</th>\n",
       "      <th>ms_per_sample</th>\n",
       "      <th>acc</th>\n",
       "      <th>err</th>\n",
       "      <th>parse_ok_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>google/gemma-3-4b-it</td>\n",
       "      <td>93</td>\n",
       "      <td>1.292481</td>\n",
       "      <td>13.897642</td>\n",
       "      <td>0.784946</td>\n",
       "      <td>0.215054</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>Qwen/Qwen2.5-7B-Instruct</td>\n",
       "      <td>93</td>\n",
       "      <td>3.778668</td>\n",
       "      <td>40.630843</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                     model  n_samples  total_time_s  ms_per_sample  \\\n",
       "0       en      google/gemma-3-4b-it         93      1.292481      13.897642   \n",
       "1       en  Qwen/Qwen2.5-7B-Instruct         93      3.778668      40.630843   \n",
       "\n",
       "        acc       err  parse_ok_rate  \n",
       "0  0.784946  0.215054            1.0  \n",
       "1  0.806452  0.193548            1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics (FA):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>model</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>total_time_s</th>\n",
       "      <th>ms_per_sample</th>\n",
       "      <th>acc</th>\n",
       "      <th>err</th>\n",
       "      <th>parse_ok_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fa</td>\n",
       "      <td>google/gemma-3-4b-it</td>\n",
       "      <td>93</td>\n",
       "      <td>1.272614</td>\n",
       "      <td>13.684027</td>\n",
       "      <td>0.731183</td>\n",
       "      <td>0.268817</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fa</td>\n",
       "      <td>Qwen/Qwen2.5-7B-Instruct</td>\n",
       "      <td>93</td>\n",
       "      <td>4.133215</td>\n",
       "      <td>44.443174</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.892473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                     model  n_samples  total_time_s  ms_per_sample  \\\n",
       "0       fa      google/gemma-3-4b-it         93      1.272614      13.684027   \n",
       "1       fa  Qwen/Qwen2.5-7B-Instruct         93      4.133215      44.443174   \n",
       "\n",
       "        acc       err  parse_ok_rate  \n",
       "0  0.731183  0.268817       1.000000  \n",
       "1  0.677419  0.322581       0.892473  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = [\n",
    "\t\"google/gemma-3-4b-it\",\n",
    "\t\"Qwen/Qwen2.5-7B-Instruct\"\n",
    "]\n",
    "\n",
    "languages = [\"en\", \"fa\"]\n",
    "results = []\n",
    "samples_by_language = {}\n",
    "PRED_COLUMN_MAP = {\n",
    "    (\"en\", \"google/gemma-3-4b-it\"): \"en_gemma\",\n",
    "    (\"fa\", \"google/gemma-3-4b-it\"): \"fa_gemma\",\n",
    "    (\"en\", \"Qwen/Qwen2.5-7B-Instruct\"): \"en_qwen\",\n",
    "    (\"fa\", \"Qwen/Qwen2.5-7B-Instruct\"): \"fa_qwen\",\n",
    "}\n",
    "\n",
    "for lang in languages:\n",
    "    print(f\"\\n=== Running language: {lang} ===\")\n",
    "    lang_samples = samples_ex.copy()\n",
    "    for m in models:\n",
    "        print(f\"Evaluating LLM model: {m}\")\n",
    "        r = evalute_llm(m, language=lang, samples_df=lang_samples)\n",
    "        results.append(r)\n",
    "        safe_name = r[\"model\"].replace(\"/\", \"_\").replace(\"-\", \"_\")\n",
    "        lang_samples[f\"llm_idx__{lang}__{safe_name}\"] = r[\"pred\"]\n",
    "        lang_samples[f\"llm_ok__{lang}__{safe_name}\"] = r[\"ok\"]\n",
    "        print(f\"acc={r['acc']:.4f} err={r['err']:.4f} parse_ok_rate={r['parse_ok_rate']:.4f}\")\n",
    "        print(f\"time={r['total_time_s']:.2f}s | {r['ms_per_sample']:.1f} ms/sample\\n\")\n",
    "        print(\"Classification report (parse_ok only):\\n\")\n",
    "        print(r[\"report_parse_ok_only\"])\n",
    "    samples_by_language[lang] = lang_samples\n",
    "\n",
    "samples_en_df = samples_by_language.get(\"en\")\n",
    "samples_fa_df = samples_by_language.get(\"fa\")\n",
    "\n",
    "samples_combined = samples_ex.copy()\n",
    "for r in results:\n",
    "    col_name = PRED_COLUMN_MAP.get((r[\"language\"], r[\"model\"]))\n",
    "    if col_name:\n",
    "        samples_combined[col_name] = r[\"pred\"]\n",
    "\n",
    "samples_ex = samples_combined\n",
    "\n",
    "metrics_columns = [\"language\", \"model\", \"n_samples\", \"total_time_s\", \"ms_per_sample\", \"acc\", \"err\", \"parse_ok_rate\"]\n",
    "metrics_df = pd.DataFrame([{k: v for k, v in r.items() if k in metrics_columns} for r in results])\n",
    "metrics_en_df = metrics_df[metrics_df[\"language\"] == \"en\"].reset_index(drop=True)\n",
    "metrics_fa_df = metrics_df[metrics_df[\"language\"] == \"fa\"].reset_index(drop=True)\n",
    "\n",
    "print(\"\\nSamples (EN) preview:\")\n",
    "display(samples_en_df.head() if samples_en_df is not None else None)\n",
    "\n",
    "print(\"\\nSamples (FA) preview:\")\n",
    "display(samples_fa_df.head() if samples_fa_df is not None else None)\n",
    "\n",
    "print(\"\\nCombined samples with prediction columns:\")\n",
    "display(samples_ex.head())\n",
    "\n",
    "print(\"\\nMetrics (EN):\")\n",
    "display(metrics_en_df)\n",
    "\n",
    "print(\"\\nMetrics (FA):\")\n",
    "display(metrics_fa_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c7b38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = samples_ex\n",
    "ac.drop('llm_idx__Qwen_Qwen2.5_7b_Instruct', axis=1, inplace=True)\n",
    "ac.drop('llm_ok__Qwen_Qwen2.5_7b_Instruct', axis=1, inplace=True)\n",
    "ac.drop('llm_idx__google_gemma_3_4b_it', axis=1, inplace=True)\n",
    "ac.drop('llm_ok__google_gemma_3_4b_it', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15143974",
   "metadata": {},
   "source": [
    "### save to xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e882f79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Ka-ChatBot_BenchMark.xlsx\n"
     ]
    }
   ],
   "source": [
    "with pd.ExcelWriter(file_path, engine=\"openpyxl\", mode='a', if_sheet_exists='replace') as writer:\n",
    "\tfaq_ex.to_excel(writer, sheet_name='faq', index=False)\n",
    "\tsamples_ex.to_excel(writer, sheet_name='samples', index=False)\n",
    "print(f\"Results saved to {file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
